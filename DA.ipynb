{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2501070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from utils.tools import *\n",
    "from torch import optim\n",
    "from utils.data_loader import *\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from Models import TADA, INFO, LSTNet, TCN, Transformer\n",
    "from thop import profile\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Time series forecasting')\n",
    "parser.add_argument('--datasets', type=str, default=\"SML2010\", help='name of datasets')\n",
    "parser.add_argument('--net', type=str, default=\"TADA\", help='name of net')\n",
    "parser.add_argument('--seq_len', type=int, default=96, help='# sequence length')\n",
    "parser.add_argument('--label_len', type=int, default=48, help='# sequence label')\n",
    "parser.add_argument('--pred_len', type=int, default=24, help='# sequence prediction')\n",
    "parser.add_argument('--feature', type=int, default=22, help='# feature')\n",
    "parser.add_argument('--hid', type=int, default=512, help='number of RNN hidden units')\n",
    "parser.add_argument('--clip', type=float, default=10., help='gradient clipping')\n",
    "parser.add_argument('--epochs', type=int, default=1, help='upper epoch limit')\n",
    "parser.add_argument('--MultiStep', type=bool, default=False, help='Multi-step prediction')\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='batch size')\n",
    "parser.add_argument('--pred_horizon', type=int, default=1, help='scope of prediction horizon')\n",
    "parser.add_argument('--n_heads', type=int, default=8, help='# attention head')\n",
    "parser.add_argument('--lr', type=float, default=1e-4)\n",
    "parser.add_argument('--freq', type=str, default=\"h\")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "for args.seq_len in [96]:\n",
    "    for args.datasets in [\"PCT\"]:\n",
    "        for args.net in [\"TADA\"]:  #\n",
    "            for args.trans in [jittering, scaling, magnitude, trans]:\n",
    "                tag = args.net + \"Ms\" if args.MultiStep else args.net\n",
    "                tag = tag + \"s\" if args.trans else tag\n",
    "\n",
    "                if args.datasets == \"ETTh\":\n",
    "                    Dataset = Dataset_ETT_hour\n",
    "                    args.feature = 7\n",
    "                elif args.datasets == \"ETTm\":\n",
    "                    Dataset = Dataset_ETT_min\n",
    "                    args.feature = 7\n",
    "                elif args.datasets == \"ELD\":\n",
    "                    Dataset = Dataset_ELD_hour\n",
    "                    args.feature = 315\n",
    "                elif args.datasets == \"Steel\":\n",
    "                    Dataset = Dataset_STI_hour\n",
    "                    args.feature = 9                    \n",
    "                elif args.datasets == \"PCT\":\n",
    "                    Dataset = Dataset_PCT_hour\n",
    "                    args.feature = 8\n",
    "\n",
    "                if args.MultiStep:\n",
    "                    args.pred_horizon = args.pred_len\n",
    "\n",
    "                e_layers = 3\n",
    "                d_layers = 2\n",
    "                for e_layers in range(3, 4):\n",
    "                    for d_layers in range(2, 3):\n",
    "                        print(f\"[INFO] \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) +\n",
    "                              f\" The {tag} is training on the Device: {try_gpu()}, Task {args.datasets}\")\n",
    "                        print(f\"[INFO] \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) +\n",
    "                              f\" Encoders: {e_layers}  Dncoders: {d_layers}\")\n",
    "\n",
    "                        for index in range(20):  #\n",
    "                            args.lr = 1e-4\n",
    "                            args.pred_len = 24\n",
    "                            print(f\"[INFO] \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) +\n",
    "                                  f\" # data in encoder: {args.seq_len}\" +\n",
    "                                  f\" # data in decoder: {args.label_len}\" +\n",
    "                                  f\" # data for prediction: {args.pred_len}\")\n",
    "\n",
    "\n",
    "                            def process(net, data, pred_len, label_len, output_attention=False):\n",
    "                                batch_x, batch_y, batch_x_mark, batch_y_mark = data\n",
    "                                dec_inp = torch.zeros([batch_y.shape[0], pred_len, batch_y.shape[-1]]).float().to(try_gpu())\n",
    "                                dec_inp = torch.cat([batch_y[:, :label_len, :], dec_inp], dim=1).float()\n",
    "\n",
    "                                batch_y = batch_y[:, label_len, :].unsqueeze(1)\n",
    "                                # encoder - decoder\n",
    "                                if output_attention:\n",
    "                                    outputs, attns = net(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "                                    return outputs, batch_y, attns\n",
    "                                outputs = net(batch_x, batch_x_mark, dec_inp, batch_y_mark)[0]\n",
    "                                return outputs, batch_y\n",
    "\n",
    "\n",
    "                            def inference_step(net, loader, process, args, output_attention=False):\n",
    "                                net.eval()\n",
    "                                net.to(try_gpu())\n",
    "                                preds = []\n",
    "                                trues = []\n",
    "                                for k, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(loader):\n",
    "                                    batch_x, batch_x_mark = batch_x.to(try_gpu()), batch_x_mark.to(try_gpu())\n",
    "                                    batch_y, batch_y_mark = batch_y.to(try_gpu()), batch_y_mark.to(try_gpu())\n",
    "                                    if k % args.pred_len == 0:\n",
    "                                        for ii in range(args.pred_len):\n",
    "                                            res = process(net, (batch_x[:, -args.seq_len:],\n",
    "                                                                batch_y[:, ii:ii + args.label_len + args.pred_horizon],\n",
    "                                                                batch_x_mark[:, -args.seq_len:],\n",
    "                                                                batch_y_mark[:,\n",
    "                                                                ii:ii + args.label_len + args.pred_horizon]),\n",
    "                                                          pred_len=args.pred_horizon,\n",
    "                                                          label_len=args.label_len,\n",
    "                                                          output_attention=output_attention)\n",
    "                                            preds.append(res[0].detach().cpu().numpy())\n",
    "                                            trues.append(res[1].detach().cpu().numpy())\n",
    "                                            batch_x = torch.cat((batch_x, res[0]), dim=1)\n",
    "                                            batch_y = torch.cat(\n",
    "                                                (batch_x, batch_y[:, ii + args.label_len + args.pred_horizon:]), dim=1)\n",
    "                                            batch_x_mark = torch.cat((batch_x_mark,\n",
    "                                                                      batch_y_mark[:, ii + args.label_len].unsqueeze(1)),\n",
    "                                                                     dim=1)\n",
    "\n",
    "                                preds = np.array(preds)\n",
    "                                trues = np.array(trues)\n",
    "                                preds = preds.reshape(-1, preds.shape[-2], preds.shape[-1])\n",
    "                                trues = trues.reshape(-1, trues.shape[-2], trues.shape[-1])\n",
    "                                if output_attention:\n",
    "                                    return preds, trues, res[2]\n",
    "                                return preds, trues\n",
    "\n",
    "\n",
    "                            def inference_multistep(net, loader, process, args, output_attention=False):\n",
    "                                net.eval()\n",
    "                                net.to(try_gpu())\n",
    "                                preds = []\n",
    "                                trues = []\n",
    "                                for k, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(loader):\n",
    "                                    batch_x, batch_x_mark = batch_x.to(try_gpu()), batch_x_mark.to(try_gpu())\n",
    "                                    batch_y, batch_y_mark = batch_y.to(try_gpu()), batch_y_mark.to(try_gpu())\n",
    "                                    if k % args.pred_len == 0:\n",
    "                                        res = process(net, (batch_x,\n",
    "                                                            batch_y,\n",
    "                                                            batch_x_mark,\n",
    "                                                            batch_y_mark),\n",
    "                                                      pred_len=args.pred_len,\n",
    "                                                      label_len=args.label_len,\n",
    "                                                      output_attention=output_attention)\n",
    "                                        preds.append(res[0].detach().cpu().numpy())\n",
    "                                        trues.append(res[1].detach().cpu().numpy())\n",
    "\n",
    "                                preds = np.array(preds)\n",
    "                                trues = np.array(trues)\n",
    "                                preds = preds.reshape(-1, 1, preds.shape[-1])\n",
    "                                trues = trues.reshape(-1, 1, trues.shape[-1])\n",
    "                                if output_attention:\n",
    "                                    return preds, trues, res[2]\n",
    "                                return preds, trues\n",
    "\n",
    "\n",
    "                            def evaluate(loader, net, criterion, args):\n",
    "                                if args.MultiStep:\n",
    "                                    preds, trues = inference_multistep(net, loader, process, args)\n",
    "                                else:\n",
    "                                    preds, trues = inference_step(net, loader, process, args)\n",
    "                                loss = criterion(torch.from_numpy(preds), torch.from_numpy(trues))\n",
    "                                return np.average(loss)\n",
    "\n",
    "\n",
    "                            def train(train_loader, net, criterion, opt, args):\n",
    "                                net.train()\n",
    "                                net.to(try_gpu())\n",
    "                                train_loss = []\n",
    "                                for batch_x, batch_y, batch_x_mark, batch_y_mark in train_loader:\n",
    "                                    batch_x, batch_x_mark = batch_x.to(try_gpu()), batch_x_mark.to(try_gpu())\n",
    "                                    batch_y, batch_y_mark = batch_y.to(try_gpu()), batch_y_mark.to(try_gpu())\n",
    "                                    opt.zero_grad()\n",
    "                                    pred, true = process(net, (batch_x, batch_y[:, :args.label_len + args.pred_horizon],\n",
    "                                                               batch_x_mark,\n",
    "                                                               batch_y_mark[:, :args.label_len + args.pred_horizon]),\n",
    "                                                         pred_len=args.pred_horizon, label_len=args.label_len)\n",
    "                                    pred = pred.type(true.dtype)\n",
    "                                    loss = criterion(pred, true)\n",
    "                                    train_loss.append(loss.item())\n",
    "                                    loss.backward()\n",
    "                                    opt.step()\n",
    "                                return np.average(train_loss)\n",
    "\n",
    "\n",
    "                            train_loader, eval_loader, test_loader = load_dataloader(\n",
    "                                args, Dataset, root_path=\"./datasets/\" + args.datasets + \"/\", transform=args.trans)\n",
    "\n",
    "                            root_path = mkdir(pred_len=\"Pred_\" + str(args.seq_len) + \"_\" + str(args.label_len),\n",
    "                                              model=tag + \"_e\" + str(e_layers) + \"d\" + str(d_layers),\n",
    "                                              augmentation= \"None\" if not args.trans else args.trans.__name__,\n",
    "                                              dataset=args.datasets, index=index)\n",
    "\n",
    "                            net = eval(args.net).Model(enc_in=args.feature, dec_in=args.feature, c_out=args.feature,\n",
    "                                                       out_len=args.pred_horizon, d_model=args.hid, n_heads=args.n_heads,\n",
    "                                                       e_layers=e_layers, d_layers=d_layers, d_ff=args.hid,\n",
    "                                                       dropout=0.1, embed='fixed', freq=args.freq, activation='relu',\n",
    "                                                       output_attention=True, mix=True, args=args)\n",
    "\n",
    "                            criterion = nn.MSELoss()\n",
    "                            opt = optim.Adam(net.parameters(), lr=args.lr)\n",
    "\n",
    "                            nParams = sum([p.nelement() for p in net.parameters()])\n",
    "                            print(f'[INFO] ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) +\n",
    "                                  ' * number of parameters: %d' % nParams, \", Learning rate: {:.1e}\".format(args.lr))\n",
    "\n",
    "                            loop = tqdm(range(1, args.epochs + 1))\n",
    "                            losses = []\n",
    "                            times = []\n",
    "                            best_eval = 1000\n",
    "                            for epoch in loop:\n",
    "                                start_time = time.time()\n",
    "                                train_loss = train(train_loader, net, criterion, opt, args)\n",
    "                                during_time = time.time() - start_time\n",
    "                                eval_losses = evaluate(eval_loader, net, criterion, args)\n",
    "                                adjust_learning_rate(opt, epoch + 1, args)\n",
    "                                if eval_losses < best_eval:\n",
    "                                    save_model(net=net, path=root_path)\n",
    "                                    best_eval = eval_losses\n",
    "                                # log loss\n",
    "                                losses.append([train_loss, eval_losses])\n",
    "                                times.append(round(during_time, 2))\n",
    "\n",
    "                                loop.set_description(\n",
    "                                    f'[INFO] {time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())} {tag},[{index}]')\n",
    "                                loop.set_postfix(\n",
    "                                    loss='Train: {:.4f}, Eval: {:.4f}, lr {:.1e})'.format(train_loss, eval_losses, args.lr))\n",
    "\n",
    "                            # load best model\n",
    "                            with open(os.path.join(root_path, \"net.pt\"), 'rb') as f:\n",
    "                                net = torch.load(f)\n",
    "\n",
    "                            print(f'[INFO] ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) +\n",
    "                                  f' Training {tag} on {args.datasets} with Pred({args.pred_len}),' +\n",
    "                                  'Best Eval Loss[{:.4f}]'.format(best_eval))\n",
    "\n",
    "                            test_criterion = nn.MSELoss()\n",
    "                            for pred_len in [24, 48, 96, 192, 336, 480]:  # , 624, 720\n",
    "                                args.pred_len = pred_len\n",
    "                                test_loader = load_dataloader(args, Dataset, root_path=\"./datasets/\" + args.datasets + \"/\")[\n",
    "                                    -1]\n",
    "                                # save test result\n",
    "                                if args.MultiStep:\n",
    "                                    Y_hat, Y, attns = inference_multistep(net, test_loader, process, args,\n",
    "                                                                          output_attention=True)\n",
    "                                else:\n",
    "                                    Y_hat, Y, attns = inference_step(net, test_loader, process, args, output_attention=True)\n",
    "                                test_eval = test_criterion(torch.from_numpy(Y_hat), torch.from_numpy(Y)).item()\n",
    "                                print(f'[INFO] ' + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) +\n",
    "                                      f' Testing {tag} on {args.datasets} with Pred({args.pred_len}),' +\n",
    "                                      'Test Loss[{:.4f}]'.format(test_eval))\n",
    "                                np.savez(os.path.join(root_path, \"result_\" + str(args.pred_len) + \".npz\"),\n",
    "                                         y=Y, y_hat=Y_hat,\n",
    "                                         loss=np.array(losses),\n",
    "                                         attns=[attn.detach().cpu() if attn is not None else None for attn in attns],\n",
    "                                         nParams=nParams,\n",
    "                                         times=round(np.array(times).mean(), 2), )\n",
    "                            print(\"\\n\")\n",
    "print(f\"[INFO] \" + time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime()) + \" Training is Done!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchG",
   "language": "python",
   "name": "torchg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
